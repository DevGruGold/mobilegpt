# ğŸ¤– MobileGPT - True Offline AI Assistant

<div align="center">

[![MobileGPT Logo](https://via.placeholder.com/128x128/000000/FFFFFF?text=ğŸ¤–)](https://github.com/DevGruGold/mobilegpt)

**The first truly offline, multimodal AI assistant that runs entirely on your device**

[![Built with React](https://img.shields.io/badge/React-18.3.1-61dafb?logo=react)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.8-3178c6?logo=typescript)](https://typescriptlang.org/)
[![Powered by Capacitor](https://img.shields.io/badge/Capacitor-6.1-119eff?logo=capacitor)](https://capacitorjs.com/)
[![Chrome AI Ready](https://img.shields.io/badge/Chrome%20AI-Gemini%20Nano-4285f4?logo=googlechrome)](https://developer.chrome.com/docs/ai/built-in)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

## âœ¨ What Makes MobileGPT Special

MobileGPT is the **first mobile-optimized AI assistant** that works completely offline with true multimodal capabilities. No internet required, no data sent to servers, no privacy concerns.

### ğŸ¯ Key Features

- ğŸ”’ **100% Offline & Private** - Your conversations never leave your device
- ğŸ–¼ï¸ **True Multimodal AI** - Analyze images, understand context, generate responses
- ğŸ“± **Mobile-First Design** - Optimized for phones and tablets with native feel
- ğŸš€ **Multiple AI Engines** - Chrome Built-in AI, WebLLM, Transformers.js, Ollama support
- âš¡ **Smart Engine Selection** - Automatically chooses the best available AI engine
- ğŸŒ™ **Adaptive Interface** - Dark/light modes with smooth animations
- ğŸ“¦ **Progressive Web App** - Install as native app with offline capabilities
- ğŸ”„ **Background Model Downloads** - Smart caching and progressive loading

## ğŸ—ï¸ Architecture & AI Engines

### Multi-Engine AI System

MobileGPT supports **4 different AI engines**, automatically selecting the best one available:

#### 1. ğŸ¥‡ **Chrome Built-in AI (Gemini Nano)** - *Primary*
- **Best Performance & Quality**
- Runs Google's Gemini Nano locally in Chrome 128+
- Full multimodal support (text + images)
- Hardware-accelerated inference
- ~4.2GB model size, auto-managed by Chrome

#### 2. ğŸ”¥ **WebLLM** - *High Performance*
- Advanced local LLMs in the browser
- Models: Llama 3.2, Qwen, Phi-3
- WebGPU acceleration when available
- Great for powerful devices (8GB+ RAM)

#### 3. ğŸŒ **Transformers.js** - *Universal Fallback*
- Works in any modern browser
- Lightweight models (~500MB)
- ONNX runtime with WebAssembly
- Broad device compatibility

#### 4. ğŸ–¥ï¸ **Ollama** - *Developer Option*
- Local server integration
- Full control over models
- Perfect for development/testing
- Requires local Ollama installation

### ğŸ“± Mobile-Native Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     React 18 + TS       â”‚  â† Modern UI framework
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Capacitor 6 Bridge    â”‚  â† Native mobile APIs
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    AI Engine Layer     â”‚  â† Smart engine selection
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Local Model Storage   â”‚  â† Offline model caching
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Device Hardware      â”‚  â† CPU/GPU/NPU optimization
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### System Requirements

- **Chrome 128+** (for best experience with Gemini Nano)
- **22GB free space** (for AI model downloads)
- **8GB+ RAM** (recommended for optimal performance)
- **Modern mobile browser** with WebAssembly support

### One-Command Setup

```bash
# Clone and run
git clone https://github.com/DevGruGold/mobilegpt.git
cd mobilegpt
npm install
npm run dev
```

### Enable Chrome Built-in AI (Recommended)

1. **Chrome Setup:**
   ```
   chrome://flags/#optimization-guide-on-device-model
   â†’ Set to "Enabled BypassPerfRequirement"
   
   chrome://flags/#prompt-api-for-gemini-nano  
   â†’ Set to "Enabled"
   ```

2. **Restart Chrome** and visit your app
3. **First Launch** will trigger model download (automatic)
4. **Monitor Progress** at `chrome://on-device-internals/`

### Build for Mobile

```bash
# Android
npm run android

# iOS (macOS only)  
npm run ios

# Progressive Web App
npm run build
# Deploy dist/ to any static hosting
```

## ğŸ’¡ Usage Examples

### Basic Chat
```typescript
// The app automatically selects the best AI engine
"Hello! How can I help you today?"
```

### Image Analysis
```typescript
// Take photo with camera or upload image
"What do you see in this image?"
// â†’ AI analyzes image and provides detailed description
```

### Multimodal Conversations
```typescript
// Upload an image of a recipe
"Can you help me modify this recipe to be vegan?"
// â†’ AI understands image content and provides suggestions
```

### Context Awareness
```typescript
"What was the main topic of our conversation?"
// â†’ AI remembers conversation context locally
```

## ğŸ› ï¸ Development

### Project Structure

```
mobilegpt/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ chat/           # Chat interface components
â”‚   â”‚   â”œâ”€â”€ ui/             # Reusable UI components
â”‚   â”‚   â””â”€â”€ onboarding/     # First-run experience
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useOfflineAI.ts # Main AI engine integration
â”‚   â”‚   â””â”€â”€ use-toast.ts    # Toast notifications
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ chat.ts         # TypeScript definitions
â”‚   â””â”€â”€ pages/
â”‚       â””â”€â”€ Index.tsx       # Main app entry point
â”œâ”€â”€ public/                 # Static assets
â”œâ”€â”€ android/               # Native Android project
â”œâ”€â”€ ios/                   # Native iOS project (if added)
â””â”€â”€ dist/                  # Built app for deployment
```

### Key Implementation Files

#### Enhanced AI Hook (`useOfflineAI.ts`)
```typescript
// Multi-engine AI system with automatic fallback
export function useOfflineAI(): UseOfflineAIReturn {
  // Chrome AI, WebLLM, Transformers.js, Ollama support
  // Automatic engine detection and selection
  // Progress tracking for model downloads
  // Error handling and recovery
}
```

#### Mobile-Optimized Chat Interface
```typescript
// Real-time streaming responses
// Camera integration for image analysis  
// Touch-optimized UI with haptic feedback
// Offline-first architecture
```

### Adding New AI Engines

```typescript
// 1. Extend the AIEngine type
export type AIEngine = 'chrome-builtin' | 'transformers' | 'webllm' | 'ollama' | 'your-engine';

// 2. Add detection function
const checkYourEngine = useCallback((): boolean => {
  return /* your detection logic */;
}, []);

// 3. Add initialization function  
const initializeYourEngine = useCallback(async () => {
  // Your engine setup code
}, []);

// 4. Add generation function
const generateWithYourEngine = async (session: any, prompt: string) => {
  // Your inference code
};
```

## ğŸ¨ Customization

### Themes & Styling
```css
/* CSS custom properties for easy theming */
:root {
  --background: 0 0% 100%;
  --foreground: 222.2 84% 4.9%;
  --primary: 221.2 83.2% 53.3%;
  --primary-foreground: 210 40% 98%;
}
```

### Model Configuration
```typescript
// Switch between AI engines programmatically
await switchEngine('webllm');    // High performance
await switchEngine('transformers'); // Universal compatibility  
await switchEngine('ollama');       // Local development
```

### UI Components
Built on shadcn/ui with full customization support:
- Consistent design system
- Accessible components  
- Mobile-optimized interactions
- Smooth animations

## ğŸ“Š Performance & Benchmarks

### Model Comparison

| Engine | Model Size | Load Time | Quality | Device Support |
|--------|------------|-----------|---------|----------------|
| Chrome AI | ~4.2GB | 30-60s | â­â­â­â­â­ | Chrome 128+ |
| WebLLM | 1-4GB | 60-120s | â­â­â­â­ | Modern browsers |
| Transformers.js | ~500MB | 15-30s | â­â­â­ | Universal |
| Ollama | Variable | 5-10s | â­â­â­â­â­ | Local server |

### Hardware Recommendations

- **Minimum:** 4GB RAM, 8GB storage
- **Recommended:** 8GB+ RAM, 32GB+ storage  
- **Optimal:** 16GB+ RAM, GPU acceleration

## ğŸ”’ Privacy & Security

### Data Handling
- **Zero server communication** for AI inference
- **Local model storage** with browser/OS security
- **No telemetry** or usage tracking
- **End-to-end privacy** for all conversations

### Security Features
- CSP (Content Security Policy) headers
- Secure model loading and verification
- Memory management for sensitive data
- Automatic cleanup of cached conversations

## ğŸš¢ Deployment Options

### Progressive Web App
```bash
npm run build
# Deploy dist/ to any static hosting service
# Automatic PWA registration and offline support
```

### Mobile App Stores
```bash
# Generate signed APK/AAB for Google Play
npm run build
npx cap build android --prod

# Generate iOS app for App Store (macOS + Xcode)
npm run build  
npx cap build ios --prod
```

### Self-Hosted
```bash
# Docker deployment
docker build -t mobilegpt .
docker run -p 3000:3000 mobilegpt

# Static hosting (Netlify, Vercel, GitHub Pages)
npm run build && npm run deploy
```

## ğŸ›£ï¸ Roadmap

### âœ… Current Features (v1.0)
- [x] Multi-engine AI support
- [x] Offline multimodal capabilities
- [x] Mobile-optimized interface
- [x] Progressive Web App
- [x] Camera integration
- [x] Smart engine selection

### ğŸ”„ In Development (v1.1)
- [ ] Voice input/output support
- [ ] Advanced image editing
- [ ] Plugin system for extensions
- [ ] Model fine-tuning interface
- [ ] Conversation export/import

### ğŸš€ Future Plans (v2.0)
- [ ] Video analysis capabilities
- [ ] Real-time collaboration
- [ ] Advanced RAG (Retrieval Augmented Generation)
- [ ] Custom model training
- [ ] Multi-language interface

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork the repository**
2. **Create feature branch:** `git checkout -b feature/amazing-feature`
3. **Commit changes:** `git commit -m 'Add amazing feature'`
4. **Push to branch:** `git push origin feature/amazing-feature`
5. **Open Pull Request**

### Development Guidelines
- Follow TypeScript strict mode
- Add tests for new features
- Update documentation
- Test on multiple devices/browsers

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Google Chrome Team** - For Chrome Built-in AI APIs
- **Hugging Face** - For Transformers.js ecosystem
- **MLC LLM Team** - For WebLLM framework
- **Ollama Community** - For local LLM serving
- **Capacitor Team** - For mobile framework
- **shadcn/ui** - For beautiful UI components

## ğŸ“ Support

### Getting Help
- ğŸ“– **Documentation:** [Setup Guide](./SETUP.md)
- ğŸ› **Bug Reports:** [GitHub Issues](https://github.com/DevGruGold/mobilegpt/issues)
- ğŸ’¬ **Discussions:** [GitHub Discussions](https://github.com/DevGruGold/mobilegpt/discussions)
- ğŸ“§ **Email:** support@mobilegpt.dev

### Community
- ğŸŒŸ **Star this repo** if you find it useful!
- ğŸ”„ **Share** with others interested in offline AI
- ğŸ¤ **Contribute** to make it even better

---

<div align="center">

**Built with â¤ï¸ for privacy-conscious AI users**

[â­ Star](https://github.com/DevGruGold/mobilegpt) â€¢ [ğŸ´ Fork](https://github.com/DevGruGold/mobilegpt/fork) â€¢ [ğŸ“ Issues](https://github.com/DevGruGold/mobilegpt/issues) â€¢ [ğŸš€ Deploy](https://github.com/DevGruGold/mobilegpt#deployment-options)

</div>